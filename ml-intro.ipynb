{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro (10 mins)\n",
    "- introduction\n",
    "- how it is related to Datathon tasks\n",
    "- training objectives and agenda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment (20 mins)\n",
    "How to set up:\n",
    "- beginners: https://colab.research.google.com\n",
    "- advanced: [instructions to set up **Docker** container](https://github.com/AntonP84/ml-intro-2019-07/blob/master/README.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jupyter](https://jupyter.org/) UI overview:\n",
    "- cells and cell types (code/markdown), output\n",
    "- kernels (Python3)\n",
    "- hotkeys (Ctrl+Enter)\n",
    "- navigation, add/remove cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install packages not available in standard Google Colab environment\n",
    "# restart the env\n",
    "!pip install -q --user shap pdpbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data (30 mins)\n",
    "- all the data is merged into a single flat table\n",
    "- one column is a **target**, other columns are **features**\n",
    "- data profiling/exploration step helps to understand the data and shape further efforts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data\n",
    "source: `https://community.watsonanalytics.com/wp-content/uploads/2015/03/WA_Fn-UseC_-HR-Employee-Attrition.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    url = 'https://github.com/AntonP84/ml-intro-2019-07/raw/master/data/WA_Fn-UseC_-HR-Employee-Attrition.csv'\n",
    "    df = pd.read_csv(url)\n",
    "except:\n",
    "    df = pd.read_csv('./data/WA_Fn-UseC_-HR-Employee-Attrition.csv')\n",
    "\n",
    "df['target'] = (df['Attrition'] == 'Yes').astype(int)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The dataframe consists of:')\n",
    "print(f'- {df.shape[0]} rows ')\n",
    "print(f'- and {df.shape[1]} columns:')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**to read later**: \n",
    "- [10 Minutes to pandas](https://pandas.pydata.org/pandas-docs/stable/getting_started/10min.html) tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore\n",
    "- profiling: check values and distributions of columns\n",
    "- graphs and plots\n",
    "- suggest ideas for data cleaning and transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attrition = df['Attrition'].value_counts(normalize=True)\n",
    "df_attrition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots with Pandas API\n",
    "df_attrition.plot.bar(title='Attrition rate is %.2f' % df_attrition[\"Yes\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots with Pandas API\n",
    "df['Age'].plot.hist()\n",
    "\n",
    "# you can use matplotlib for customization\n",
    "plt.xlabel('Age')\n",
    "plt.title('Histogram for Age');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# one line to get a simple plot\n",
    "df['StockOptionLevel'].value_counts().plot.bar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... but you are not expected to do it manually for every single column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**to read later**:\n",
    "- pandas Visualization [Guide](https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automated with pandas_profiling\n",
    "\n",
    "- basic plots and summaries for every column\n",
    "- warnings about potential issues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ProfileReport(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**for discussion**:\n",
    "- some columns (e.g., `Over18` and `StandardHours`) are constant and useless for analysis. Check it. Should we drop them?\n",
    "- some columns (e.g., `StockOptionLevel` and `YearsSinceLastPromotion`) have many zeroes. Check it. Should we drop them?\n",
    "- some columns (e.g., `MonthlyIncome` and `JobLevel`) are highly correlated. Should we drop them?\n",
    "- `EmployeeNumber`, is it employee_id? Should we keep it?\n",
    "\n",
    "- any ideas for Feature Engineering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('EmployeeNumber')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reminder: Business case slide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Encode your domain expertise, intuition and ideas into new columns to help ML perform better / faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new columns: years as percentage of YearsAtCompany\n",
    "cols_years = ('YearsInCurrentRole', 'YearsSinceLastPromotion', 'YearsWithCurrManager')\n",
    "cols_new = [v + '_pct' for v in cols_years]\n",
    "\n",
    "for col_years, col_new in zip(cols_years, cols_new):\n",
    "    df[col_new] = df[col_years] / df['YearsAtCompany']\n",
    "    \n",
    "print('Added derived columns, with percentage of years:')\n",
    "print(cols_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check what we got\n",
    "df[cols_new].describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform\n",
    "for ML you need:\n",
    "- **target**: column you want to predict, denoted as *y*\n",
    "- **features**: columns you use for prediction, denoted as *X*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['target']\n",
    "X = df.drop(columns=['Attrition', 'target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical columns\n",
    "for ML you need *numerical* features. Apply `LabelEncoder` on \n",
    "- columns with textual names of categories\n",
    "- columns with numeric codes of categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Before')\n",
    "X[['BusinessTravel', 'StockOptionLevel']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "cols_str = X.select_dtypes('object').columns.tolist()\n",
    "cols_coded = ['JobLevel', 'StockOptionLevel', 'Education', \n",
    "              'EnvironmentSatisfaction', 'JobInvolvement', 'JobSatisfaction', \n",
    "              'PerformanceRating', 'RelationshipSatisfaction', 'WorkLifeBalance'\n",
    "             ]\n",
    "\n",
    "cols_categorical = cols_str + cols_coded\n",
    "\n",
    "for col in cols_categorical:\n",
    "    X[col] = LabelEncoder().fit_transform(X[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('After')\n",
    "X[['BusinessTravel', 'StockOptionLevel']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**to read later**:\n",
    "- examples in `LabelEncoder` [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)\n",
    "\n",
    "**for discussion**:\n",
    "- should we apply [other preprocessing transformations](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing) from `sklearn` package (e.g., scaling, normalization, one-hot-encoding)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning model (40 mins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling\n",
    "split the data into two parts:\n",
    "- **train** sample is used to train the model\n",
    "- **test** sample is used to test model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2019)\n",
    "\n",
    "print('Size of the train sample:', len(X_train))\n",
    "print('Size of the test sample:', len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model\n",
    "- **Gradient Boosting** is fast, accurate and flexible ML model\n",
    "- details are not on the agenda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the workflow is:\n",
    "1. **train** the model on the train sample\n",
    "1. **test** the model on the test sample\n",
    "1. **use** the model to get predictions and other info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "model = LGBMClassifier()  # with default parameters\n",
    "model.fit(X_train, y_train, categorical_feature=cols_categorical)\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**for discussion**:\n",
    "- can we get a good model without knowing what is inside using default parameters?\n",
    "- ML model training was fast, is it ok?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model\n",
    "Select evaluation metric according to the use case.\n",
    "\n",
    "There are a lot of metrics (cf. [metrics available in `sklearn`](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics)), but **precision** and **recall** are applied most of the time.\n",
    "\n",
    "**Precision at k** for the current problem:\n",
    "1. score the employees\n",
    "1. select top 5% most likely to leave the company\n",
    "1. among those, calculate the share of employees who actually left the company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score the employees\n",
    "predictions_test = model.predict_proba(X_test)[:, 1]\n",
    "predictions_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "threshold = np.percentile(predictions_test, 95)\n",
    "precision = precision_score(y_test, predictions_test > threshold)\n",
    "print(f'Model precision is {precision:.1%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Employees most likely to leave the company:')\n",
    "\n",
    "(\n",
    "    X_test\n",
    "    .assign(confidence=predictions_test)\n",
    "    .sort_values(by='confidence', ascending=False)['confidence']\n",
    "    .head()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reveal driving factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# load JS visualization code to notebook\n",
    "shap.initjs()\n",
    "\n",
    "# explain the model's predictions using SHAP values\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### global\n",
    "aka **driving factors** - which factors the model considers to be the most important for the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_test, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### local\n",
    "which factors drive the outcome *for each particular data point*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the prediction with the highest attrition score\n",
    "id_ = predictions_test.argmax()\n",
    "\n",
    "employee_number = X_test.iloc[id_].name\n",
    "features = df.drop(columns=['target', 'Attrition']).loc[employee_number, :]\n",
    "\n",
    "print('Model output:')\n",
    "print(predictions_test[id_])\n",
    "print()\n",
    "\n",
    "print('Feature values:')\n",
    "print(features)\n",
    "\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value, shap_values[id_,:], features)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the prediction with the lowest attrition score\n",
    "id_ = predictions_test.argmin()\n",
    "\n",
    "employee_number = X_test.iloc[id_].name\n",
    "features = df.drop(columns=['target', 'Attrition']).loc[employee_number, :]\n",
    "\n",
    "print('Model output:')\n",
    "print(predictions_test[id_])\n",
    "print()\n",
    "\n",
    "print('Feature values:')\n",
    "print(features)\n",
    "\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value, shap_values[id_,:], features)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### explore relationships\n",
    "to gain insights and understand the relationship btw attrition and key factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdpbox import pdp, info_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_plots.target_plot(\n",
    "    df=df, feature='MonthlyIncome', feature_name='MonthlyIncome', target='target'\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_plots.target_plot(\n",
    "    df=df, feature='Age', feature_name='Age', target='target'\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = X_test.copy()\n",
    "df_test['predictions'] = predictions_test\n",
    "df_test['target'] = y_test\n",
    "\n",
    "info_plots.target_plot(\n",
    "    df=df_test, feature='predictions', feature_name='predictions', target='target'\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**for discussion:**\n",
    "- we calculated *Precision@k*, but never used it. Why?\n",
    "- we have ML model. What is the next step?\n",
    "\n",
    "**exercise**:\n",
    "- can you make ML model more precise by changing its parameters? Parameters are described [in the documentation](https://lightgbm.readthedocs.io/en/latest/Parameters.html#core-parameters). Too many of them. Hint: as the model is based on decision *trees*, you can try `num_trees`, `num_leaves`, `min_data_in_leaf` as a starting point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment of the ML model (10 mins)\n",
    "**Warning**: Colab is not the best place for model deployment. Switch back to your environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [MLFlow](https://jupyter.org/) Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "\n",
    "class Classifier(LGBMClassifier):\n",
    "    def predict(self, X):\n",
    "        return self.predict_proba(X)[:, 1]\n",
    "    \n",
    "\n",
    "def make_experiment(num_leaves=31):\n",
    "    \"\"\"create an experiment for different values of num_leaves\"\"\"\n",
    "    with mlflow.start_run():\n",
    "        # train model\n",
    "        model = Classifier(num_leaves=num_leaves)       # try non-default parameter values\n",
    "        model.fit(X_train, y_train, categorical_feature=cols_categorical)\n",
    "\n",
    "        # evaluate model\n",
    "        predictions_test = model.predict(X_test)\n",
    "        threshold = np.percentile(predictions_test, 95)\n",
    "        y_pred = predictions_test > threshold\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)           # add recall metric\n",
    "\n",
    "        # log results and save artifacts\n",
    "        mlflow.log_param(\"num_leaves\", num_leaves)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_leave=31 by default\n",
    "for num_leaves in [2, 4, 8, 16, 31, 64]:\n",
    "    make_experiment(num_leaves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run and go to MLFlow UI http://localhost:5000\n",
    "# record the id of default model\n",
    "!mlflow server --host 0.0.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env MLFLOW_CONDA_HOME=/home/user/anaconda3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!mlflow models serve -m ./mlruns/0/a93fe5e7501e4f9dbd21ebafcc94bdbe/artifacts/model -p 1234 --no-conda --host 0.0.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**exercise**:\n",
    "- verify predictions in the notebook vs. in the served model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_ = predictions_test.argmin()\n",
    "features = X_test.iloc[[id_], :]\n",
    "\n",
    "# values of features for the request\n",
    "request_data = features.to_json(orient='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command =  'curl -X POST -H \"Content-Type:application/json; format=pandas-split\" '\n",
    "command += f\"--data '{request_data}' \"\n",
    "command += 'http://127.0.0.1:1234/invocations'\n",
    "\n",
    "print('Command to execute:\\n')\n",
    "print(command)\n",
    "print()\n",
    "\n",
    "print('Verify predictions. You are expected to get the following value from the served model:')\n",
    "print(predictions_test[id_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q&A (10 mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "292.313px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
